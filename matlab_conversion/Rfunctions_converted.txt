#### checkseq depth

library(MASS)

checkseqdepth <- function(taseqcontrol) {
  totalsequences <- sum(taseqcontrol)
  tahit <- taseqcontrol[taseqcontrol != 0]
  fractionhit <- length(tahit) / length(taseqcontrol)
  taprop <- taseqcontrol / totalsequences
  
  sensitivityanalysis <- matrix(nrow = 1000, ncol = 2)
  
  for (i in seq(1, totalsequences, by = 100000)) {
    x <- apply(rmultinom(1, i, taprop), 2, as.logical)
    x <- rowSums(x)
    z <- mean(x)
    sensitivityanalysis[ceiling(i / 100000), 1] <- i
    sensitivityanalysis[ceiling(i / 100000), 2] <- z
  }
  
  plot(sensitivityanalysis[, 1], sensitivityanalysis[, 2], pch = 20, xlab = "Sequence Depth", ylab = "Mean Hits")
  
  return(sensitivityanalysis)
}



##### correct positional bias

window_average <- function(TAsites, Total_reads, windowsize, genome_length) {
  # Sets up the genomic window that you want with the first window starting at the first nt
  num_windows <- genome_length / windowsize # calculates how many windows you will create
  windowfix <- floor(num_windows) # rounds down the number of window
  leftover_window_start <- (windowfix * windowsize) + 1
  leftover_window_end <- (windowfix * windowsize) + (genome_length - (windowfix * windowsize)) # uses the remaining reads to define

  nonzeroindices <- which(Total_reads > 0) # finds where sites with reads are in the list from TAsites or Tn5sites
  TAsites_nonzero <- TAsites[nonzeroindices]
  reads_nonzero <- Total_reads[nonzeroindices] # pulls out the reads at each insertion when they are >0

  chr_ave <- sum(Total_reads) / length(reads_nonzero) # calculates chromosomal read average at all sites with reads

  # Iterates through the windows to calculate the window average and scaling factor, and adjusts the reads accordingly
  TA_window_indice <- rep(0, length(nonzeroindices))
  TA_window_reads <- rep(0, windowfix)
  counter <- rep(0, windowfix)

  for (x in 1:windowfix) {
    for (p in 1:length(nonzeroindices)) {
      if (TAsites_nonzero[p] >= ((x * windowsize) - windowsize + 1) & TAsites_nonzero[p] <= (x * windowsize)) {
        TA_window_indice[p] <- x
        counter[x] <- counter[x] + 1
        TA_window_reads[x] <- TA_window_reads[x] + reads_nonzero[p] # running total of all reads that fit in each window
      }
    }
  }

  mean_reads <- TA_window_reads / counter # for main windows, calculate the reads in each window
  scale <- chr_ave / mean_reads # the scale factor is to be multiplied to the reads in each window

  corrected_reads <- rep(0, length(TA_window_indice))
  normalized_reads <- rep(0, length(Total_reads))

  for (x in 1:length(TA_window_indice)) {
    if (TA_window_indice[x] > 0) {
      window_scalar <- scale[TA_window_indice[x]]
      corrected_reads[x] <- round(reads_nonzero[x] * window_scalar) # scale each read to the correction factor calculated for the window
      normalized_reads[nonzeroindices[x]] <- corrected_reads[x]
    }
  }

  # Performs the same functions for the last leftover sequence
  TA_window_indice <- rep(0, length(nonzeroindices)) # reset TA_window_indice so you don't calculate the past window data again
  TA_window_reads <- rep(0, windowfix + 1)
  counter <- rep(0, windowfix + 1)

  for (p in 1:length(nonzeroindices)) {
    if (TAsites_nonzero[p] >= leftover_window_start & TAsites_nonzero[p] <= leftover_window_end) {
      TA_window_indice[p] <- windowfix + 1
      counter[windowfix + 1] <- counter[windowfix + 1] + 1
      TA_window_reads[windowfix + 1] <- TA_window_reads[windowfix + 1] + reads_nonzero[p] # running total of all reads that fit in each window
    }
  }

  mean_reads <- TA_window_reads / counter
  scale <- chr_ave / mean_reads

  for (x in 1:length(TA_window_indice)) {
    if (TA_window_indice[x] > 0) {
      window_scalar <- scale[TA_window_indice[x]]
      corrected_reads[x] <- round(reads_nonzero[x] * window_scalar)
      normalized_reads[nonzeroindices[x]] <- corrected_reads[x]
    }
  }

  return(normalized_reads)
}




##### sliding window

library(stats)

Slidingwindow <- function(taseq, bootstraps, windowsize, uniquenames, uniqueindices, threshold) {
  # first generate nbootstraps of size windowsize
  # during this score all bootstraps for % TAs that are not empty and total
  # tas hit
  boots <- matrix(sample(length(taseq), windowsize * bootstraps, replace = TRUE), nrow = windowsize, ncol = bootstraps)
  bootstats <- matrix(0, nrow = 2, ncol = bootstraps)
  essentialregions <- rep(0, length(taseq))
  essentiallist <- rep(0, length(uniquenames))
  essentialpvals <- rep(0, length(taseq))

  for (i in 1:bootstraps) {
    taboots <- taseq[boots[, i], 1]
    totalta <- sum(taboots)
    numbernothit <- sum(taboots == 0)
    numberhit <- sum(taboots != 0)
    fractionhit <- numberhit / (numberhit + numbernothit)
    bootstats[1, i] <- totalta
    bootstats[2, i] <- fractionhit
  }

  for (i in 1:length(taseq)) {
    windowval <- 0
    if (length(taseq) - i >= windowsize) {
      windowval <- taseq[i:(i + windowsize - 1)]
      sumwindowval <- sum(windowval)
      probofgettincurrentwindow <- pnorm(sumwindowval, mean(bootstats[1, ]), sd(bootstats[1, ]))
      essentialpvals[i] <- probofgettincurrentwindow
      if (probofgettincurrentwindow < threshold) {
        essentialregions[i:(i + windowsize - 1)] <- 1
      }
    } else {
      windowval <- c(taseq[i:length(taseq)], taseq[1:(i - 1)])
      sumwindowval <- sum(windowval)
      probofgettincurrentwindow <- pnorm(sumwindowval, mean(bootstats[1, ]), sd(bootstats[1, ]))
      essentialpvals[i] <- probofgettincurrentwindow
      if (probofgettincurrentwindow < threshold) {
        essentialregions[i:length(taseq)] <- 1
      }
    }
  }

  for (i in 1:length(uniquenames)) {
    essentialfeatures <- essentialregions[uniqueindices[i, 1]:uniqueindices[i, 2]]
    if (sum(essentialfeatures) == length(essentialfeatures)) {
      essentiallist[i] <- 1
    }
  }

  return(list(essentialregions = essentialregions, essentiallist = essentiallist, bootstats = bootstats, essentialpvals = essentialpvals))
}



##### discretize

discretize5 <- function(TAarray, zero, one, sevfive, whisker) {
  discta <- vector(length = length(TAarray))
  for (i in 1:length(TAarray)) {
    if (TAarray[i, 1] == zero) {
      discta[i] <- 1
    } else if (TAarray[i, 1] > 0 && TAarray[i, 1] <= one) {
      discta[i] <- 2
    } else if (TAarray[i, 1] > one && TAarray[i, 1] < sevfive) {
      discta[i] <- 3
    } else if (TAarray[i, 1] > (sevfive - 1) && TAarray[i, 1] < whisker) {
      discta[i] <- 4
    } else if (TAarray[i, 1] > (whisker - 1)) {
      discta[i] <- 5
    }
  }
  return(discta)
}



#### hmm estimate


#### hmmconverge

library(HMM)

hmmconverge <- function(genometa, initialtrans, initialemission) {
  i <- 1
  m <- nrow(genometa)
  n <- ncol(genometa)
  outmat <- matrix(0, nrow = m, ncol = 100)
  a <- initialtrans
  b <- initialemission
  j <- 1
  
  while (i > 0) {
    a_0 <- a
    b_0 <- b
    states <- hmmviterbi(genometa, a_0, b_0)
    hmmfit <- hmmestimate(genometa, states)
    a <- hmmfit$A
    b <- hmmfit$B
    outmat[, j] <- states
    i <- (a[1, 1] - a_0[1, 1])
    j <- j + 1
  }
  
  return(list(outmat = outmat, a_0 = a_0, b_0 = b_0))
}


library(dplyr)

output_essential <- function(finalessential, uniquenames, uniqueindices) {
  # Goes through and finds all annotations that have essential regions
  # You get a 1 for non essential, 2 for essential
  outputessential <- rep(0, length(uniqueindices))
  callstats <- rep(0, 3)
  
  for (i in 1:length(uniqueindices)) {
    annotcallsess <- finalessential[uniqueindices[i, 1]:uniqueindices[i, 2], 1]
    len_ce <- length(annotcallsess)
    x <- round(len_ce * 0.20)
    if (x == 0) {
      x <- 1
    }
    min_ce <- min(annotcallsess[x:(len_ce - x)])
    max_ce <- max(annotcallsess[x:(len_ce - x)])
    outputessential[i] <- 1
    if (max_ce > 1) {
      outputessential[i] <- 3
      if (min_ce > 1) {
        outputessential[i] <- 2
      }
    }
    callstats[outputessential[i]] <- callstats[outputessential[i]] + 1
  }
  
  return(list(outputessential = outputessential, callstats = callstats))
}



library(stats)

simulateequalsaturation <- function(taproportion, reads, inputreads, boots) {
  # taproportion is the gap in ta density between libraries
  # reads is the number of reads to simulate. Reads should equal the total
  # number of reads in the experimental condition that you want to compare to
  inputreadssum <- sum(inputreads)
  inputproportion <- inputreads / inputreadssum
  inputproportiontanorm <- inputproportion * taproportion
  inputproportiontanorm <- c(inputproportiontanorm, 1 - taproportion)
  multinominputsample <- rmultinom(boots, reads, inputproportiontanorm)
  multinominputsample <- t(multinominputsample)
  multisum <- rowSums(multinominputsample)
  difference <- multisum - multinominputsample[nrow(multinominputsample), 1]
  correction <- matrix(reads / difference, nrow = nrow(multinominputsample), ncol = 1)
  correctedinput <- multinominputsample * correction
  bootstrapcontrol <- correctedinput[1:length(inputreads), ]
  return(bootstrapcontrol)
}



runmwuallboots <- function(bootcontrols, experiment, tauniquenames, tauniqueindices) {
  # Run the bootstrapreplicates
  m <- nrow(bootcontrols)
  n <- ncol(bootcontrols)
  MWUboots <- matrix(0, nrow = length(tauniqueindices), ncol = n)
  for (i in 1:n) {
    MWUpvalvector <- MWUbytransposon(experiment, bootcontrols[, i], tauniquenames, tauniqueindices)
    MWUboots[, i] <- MWUpvalvector
  }
  return(MWUboots)
}




library(stats)

MWUsummarystats <- function(MWU_across_all_boots, pvalue_desired, significant_proportion, uniqueindices, Controlsims, Experiment) {
  m <- nrow(MWU_across_all_boots)
  n <- ncol(MWU_across_all_boots)
  MWUsummary <- matrix(0, nrow = m, ncol = 6)

  for (i in 1:m) {
    row <- MWU_across_all_boots[i, ]
    instances_below <- row[row <= pvalue_desired]
    if (length(instances_below) > 0) {
      proportion <- length(instances_below) / n
      MWUsummary[i, 1] <- proportion
      if (proportion >= significant_proportion) {
        MWUsummary[i, 2] <- 1
      }
    }
  }

  for (i in 1:m) {
    norm_MWU <- rep(0, ncol(MWU_across_all_boots))
    for (j in 1:ncol(MWU_across_all_boots)) {
      if (is.na(MWU_across_all_boots[i, j])) {
        norm_MWU[j] <- 1
      } else {
        norm_MWU[j] <- MWU_across_all_boots[i, j]
      }
    }
    MWUsummary[i, 3] <- mean(norm_MWU)
    MWUsummary[i, 4] <- sd(norm_MWU)
  }

  ctrl_sum <- 0
  exp_sum <- 0
  count_ratio <- matrix(0, nrow = length(uniqueindices), ncol = ncol(Controlsims))

  for (y in 1:ncol(Controlsims)) {
    for (x in 1:length(uniqueindices)) {
      for (p in uniqueindices[x, 1]:uniqueindices[x, 2]) {
        ctrl_sum <- Controlsims[p, y] + ctrl_sum
        exp_sum <- Experiment[p] + exp_sum
        ratio <- exp_sum / ctrl_sum
      }
      if (ratio > 0) {
        count_ratio[x, y] <- ratio
      }
      if (is.nan(exp_sum / ctrl_sum)) {
        count_ratio[x, y] <- 0
      }
      if (is.infinite(ratio)) {
        count_ratio[x, y] <- exp_sum
      }
      if (ratio == 0) {
        count_ratio[x, y] <- 1 / ctrl_sum
      }
      ctrl_sum <- 0
      exp_sum <- 0
      ratio <- 0
    }
  }

  for (z in 1:m) {
    MWUsummary[z, 5] <- mean(count_ratio[z, ])
    MWUsummary[z, 6] <- sd(count_ratio[z, ])
  }

  return(MWUsummary)
}


library(HMM)

hmmtrainmwu <- function(experiment, controlbootstraps, trainingstates, uniquenames, uniqueindices, mwuthr, denominator1, denominator2, denominator3, q1, q2, q3, q4) {
  # Get the number of columns in controlbootstraps
  n <- ncol(controlbootstraps)
  
  # Initialize the output matrices
  hmmmatrix <- matrix(0, nrow = nrow(experiment), ncol = n)
  trainingmatrix <- matrix(0, nrow = nrow(experiment), ncol = n)
  
  for (i in 1:n) {
    # Step 1: Discretize
    discta <- discretizeconditional_3(experiment, controlbootstraps[, i], denominator1, denominator2, denominator3, q1, q2, q3, q4)
    
    mwutrain <- trainingstates
    aucmwutrain <- trainingstates
    
    for (j in 1:length(uniquenames)) {
      ratio <- sum(experiment[uniqueindices[j, 1]:uniqueindices[j, 2], 1]) / sum(controlbootstraps[uniqueindices[j, 1]:uniqueindices[j, 2], i])
      labels <- c(rep(0, uniqueindices[j, 2] - uniqueindices[j, 1] + 1), rep(1, uniqueindices[j, 2] - uniqueindices[j, 1] + 1))
      scores1 <- experiment[uniqueindices[j, 1]:uniqueindices[j, 2], 1]
      scores2 <- controlbootstraps[uniqueindices[j, 1]:uniqueindices[j, 2], i]
      p <- wilcox.test(scores1, scores2)$p.value
      
      if (ratio > 1) {
        if (p < mwuthr) {
          mwutrain[uniqueindices[j, 1]:uniqueindices[j, 2]] <- 3
        }
      }
      if (ratio < 1) {
        if (p < mwuthr) {
          mwutrain[uniqueindices[j, 1]:uniqueindices[j, 2]] <- 4
        }
      }
    }
    
    truse <- hmmestimate(discta, mwutrain)$transition
    em <- hmmestimate(discta, mwutrain)$emission
    hmm <- hmmviterbi(discta, truse, em)
    hmmmatrix[, i] <- hmm
    trainingmatrix[, i] <- mwutrain
  }
  
  stateconfidence <- matrix(0, nrow = nrow(experiment), ncol = max(hmmmatrix))
  for (j in 1:nrow(experiment)) {
    for (k in 1:n) {
      stateconfidence[j, hmmmatrix[j, k]] <- stateconfidence[j, hmmmatrix[j, k]] + 1
    }
  }
  stateconfidence <- stateconfidence / n
  
  return(list(hmmmatrix = hmmmatrix, stateconfidence = stateconfidence, trainingmatrix = trainingmatrix))
}

discretizeconditional_3 <- function(experiment, controlbootstraps, denominator1, denominator2, denominator3, q1, q2, q3, q4) {
  # Implement the discretizeconditional_3 function in R
  # This function should take the same input parameters as the MATLAB version
  # and return the discretized data
}




library(dplyr)

callconditional <- function(stateconfidence, uniquenames, uniqueindices, minsl, maxsl, minenr, maxenr, propignore) {
  outputcond <- rep(0, nrow(uniqueindices))
  callstats <- rep(0, 5)
  
  for (i in 1:nrow(uniqueindices)) {
    annotcallsl <- stateconfidence[uniqueindices[i, 1]:uniqueindices[i, 2], 4]
    annotcallenr <- stateconfidence[uniqueindices[i, 1]:uniqueindices[i, 2], 3]
    len_ce <- length(annotcallsl)
    len_enr <- length(annotcallenr)
    x <- round(len_ce * propignore)
    if (x == 0) {
      x <- 1
    }
    min_ce <- min(annotcallsl[x:(len_ce-x)])
    max_ce <- max(annotcallsl[x:(len_ce-x)])
    min_enr <- min(annotcallenr[x:(len_enr-x)])
    max_enr <- max(annotcallenr[x:(len_enr-x)])
    outputcond[i] <- 5
    if (max_ce >= maxsl) {
      outputcond[i] <- 1
      if (min_ce >= minsl) {
        outputcond[i] <- 2
      }
    }
    if (max_enr >= maxenr) {
      outputcond[i] <- 3
      if (min_enr >= minenr) {
        outputcond[i] <- 4
      }
    }
    callstats[outputcond[i]] <- callstats[outputcond[i]] + 1
  }
  
  return(list(outputcond = outputcond, callstats = callstats))
}